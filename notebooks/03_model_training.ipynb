{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU","kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":12580315,"sourceType":"datasetVersion","datasetId":7945153}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Fraud Detection - Model Training and Imbalanced Data Handling\n","metadata":{"id":"QtHc8_vOQDk6"}},{"cell_type":"code","source":"# Force compatible versions to fix binary incompatibility\n!pip install -U numpy==1.23.5 scikit-learn==1.3.2 imbalanced-learn==0.11.0 --quiet\n!pip install -U xgboost lightgbm tqdm joblib matplotlib seaborn pandas --quiet\n","metadata":{"id":"wVBh9vofTeCq","trusted":true,"execution":{"iopub.status.busy":"2025-07-26T06:20:25.070917Z","iopub.execute_input":"2025-07-26T06:20:25.071469Z","iopub.status.idle":"2025-07-26T06:20:32.795761Z","shell.execute_reply.started":"2025-07-26T06:20:25.071442Z","shell.execute_reply":"2025-07-26T06:20:32.794884Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# ✅ Core Libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pickle\nimport warnings\nfrom collections import Counter\n\n# ✅ Machine Learning Models\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.neural_network import MLPClassifier\nimport xgboost as xgb\nimport lightgbm as lgb\n\n# ✅ Model Selection & Evaluation\nfrom sklearn.model_selection import (\n    cross_val_score, StratifiedKFold, GridSearchCV, RandomizedSearchCV\n)\nfrom sklearn.metrics import (\n    classification_report, confusion_matrix, roc_auc_score,\n    average_precision_score, f1_score, precision_score, recall_score,\n    precision_recall_curve\n)\n\n# ✅ Utilities\nfrom sklearn.utils.class_weight import compute_class_weight\nfrom tqdm import tqdm\nimport joblib\n\n# ✅ Handle Imbalanced Data\nfrom imblearn.over_sampling import SMOTE, ADASYN, BorderlineSMOTE\nfrom imblearn.under_sampling import RandomUnderSampler, EditedNearestNeighbours\nfrom imblearn.combine import SMOTETomek, SMOTEENN\nfrom imblearn.ensemble import BalancedRandomForestClassifier, BalancedBaggingClassifier\n\n# ✅ Configurations\nwarnings.filterwarnings('ignore')\nnp.random.seed(42)\n\nprint(\"✅ All libraries imported successfully.\")\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6YUBkYK_Td_j","outputId":"a8994789-6633-4896-d6f9-e83580694f55","trusted":true,"execution":{"iopub.status.busy":"2025-07-26T06:20:32.797169Z","iopub.execute_input":"2025-07-26T06:20:32.797381Z","iopub.status.idle":"2025-07-26T06:20:35.228425Z","shell.execute_reply.started":"2025-07-26T06:20:32.797357Z","shell.execute_reply":"2025-07-26T06:20:35.227676Z"}},"outputs":[{"name":"stdout","text":"✅ All libraries imported successfully.\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"## 1. Load Preprocessed Data","metadata":{"id":"CpoICfAKQDk_"}},{"cell_type":"code","source":"import pandas as pd\n\n# Load the training set\ndf_train = pd.read_csv('/kaggle/input/result/X_cc_train_scaled.csv')\nprint(df_train.head())\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qPd8dpvnUz9L","outputId":"836fcf7b-78fa-44bf-9303-80b24d67724b","trusted":true,"execution":{"iopub.status.busy":"2025-07-26T06:20:35.229117Z","iopub.execute_input":"2025-07-26T06:20:35.229561Z","iopub.status.idle":"2025-07-26T06:20:38.388008Z","shell.execute_reply.started":"2025-07-26T06:20:35.229540Z","shell.execute_reply":"2025-07-26T06:20:38.387135Z"}},"outputs":[{"name":"stdout","text":"         V1        V2        V3        V4        V5        V6        V7  \\\n0  0.993379 -0.456037 -0.894052 -0.467284  1.089217  3.024383 -1.194852   \n1  1.038507 -0.029349 -2.018302  0.175133  2.133506  2.478840 -0.001832   \n2 -0.506766  0.366065  0.470114 -0.700918 -0.598748  1.470411 -1.786684   \n3  1.166419 -0.909447 -0.493095 -1.178149 -1.010692 -0.262292 -1.153123   \n4 -0.229485 -0.613041  0.076742 -2.440089  0.518711 -0.109914  0.407186   \n\n         V8        V9       V10  ...  v_features_mean  v_features_std  \\\n0  0.957057  1.281376 -0.144546  ...         1.292780        0.371626   \n1  0.566704  0.041121  0.262604  ...         0.979321        0.467642   \n2 -4.227592  0.000064 -1.849641  ...        -1.531851        1.113362   \n3  0.008765 -1.019866  1.617041  ...        -1.160232       -0.069793   \n4 -0.095161 -0.041449 -0.514215  ...        -1.708207       -0.033004   \n\n   v_features_max  v_features_min  v_features_range  amount_category_Very Low  \\\n0        1.547740        0.333571          0.496266                  1.377324   \n1        0.959253       -0.591984          0.811876                  1.377324   \n2       -0.128557       -1.751881          1.047398                 -0.726045   \n3        0.138410        0.223106         -0.077652                  1.377324   \n4       -0.419198       -0.824195          0.328930                 -0.726045   \n\n   amount_category_Low  amount_category_Medium  amount_category_High  \\\n0            -0.684214               -0.387726             -0.447552   \n1            -0.684214               -0.387726             -0.447552   \n2            -0.684214               -0.387726              2.234379   \n3            -0.684214               -0.387726             -0.447552   \n4            -0.684214                2.579141             -0.447552   \n\n   amount_category_Very High  \n0                  -0.181547  \n1                  -0.181547  \n2                  -0.181547  \n3                  -0.181547  \n4                  -0.181547  \n\n[5 rows x 59 columns]\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"import pandas as pd\nimport pickle\nfrom collections import Counter\n\nprint(\"Loading preprocessed data...\")\n\n# Fraud data\nX_fraud_train = pd.read_csv('/kaggle/input/result/X_fraud_train_scaled.csv')\nX_fraud_test = pd.read_csv('/kaggle/input/result/X_fraud_test_scaled.csv')\ny_fraud_train = pd.read_csv('/kaggle/input/result/y_fraud_train.csv').squeeze()\ny_fraud_test = pd.read_csv('/kaggle/input/result/y_fraud_test.csv').squeeze()\n\n# Credit card data\nX_cc_train = pd.read_csv('/kaggle/input/result/X_cc_train_scaled.csv')\nX_cc_test = pd.read_csv('/kaggle/input/result/X_cc_test_scaled.csv')\ny_cc_train = pd.read_csv('/kaggle/input/result/y_cc_train.csv').squeeze()\ny_cc_test = pd.read_csv('/kaggle/input/result/y_cc_test.csv').squeeze()\n\n# Load feature information\nwith open('/kaggle/input/result/feature_info.pkl', 'rb') as f:\n    feature_info = pickle.load(f)\n\n# Print dataset shapes\nprint(f\"Fraud data - Train: {X_fraud_train.shape}, Test: {X_fraud_test.shape}\")\nprint(f\"Credit card data - Train: {X_cc_train.shape}, Test: {X_cc_test.shape}\")\n\n# Class distribution\nprint(f\"\\nFraud data class distribution: {Counter(y_fraud_train)}\")\nprint(f\"Credit card data class distribution: {Counter(y_cc_train)}\")\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UXtlmVbIQDk_","outputId":"c5427076-63fe-468f-d980-fa979bd479ad","trusted":true,"execution":{"iopub.status.busy":"2025-07-26T06:20:38.390035Z","iopub.execute_input":"2025-07-26T06:20:38.390264Z","iopub.status.idle":"2025-07-26T06:20:51.592815Z","shell.execute_reply.started":"2025-07-26T06:20:38.390246Z","shell.execute_reply":"2025-07-26T06:20:51.592001Z"}},"outputs":[{"name":"stdout","text":"Loading preprocessed data...\nFraud data - Train: (120889, 223), Test: (30223, 223)\nCredit card data - Train: (227845, 59), Test: (56962, 59)\n\nFraud data class distribution: Counter({0: 109568, 1: 11321})\nCredit card data class distribution: Counter({0: 227451, 1: 394})\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"## 2. Imbalanced Data Handling Techniques","metadata":{"id":"zojFyAb4QDlA"}},{"cell_type":"code","source":"def apply_sampling_strategy(X, y, strategy='smote', random_state=42):\n    \"\"\"Apply different sampling strategies to handle imbalanced data\"\"\"\n\n    if strategy == 'none':\n        return X, y\n\n    elif strategy == 'smote':\n        sampler = SMOTE(random_state=random_state)\n\n    elif strategy == 'adasyn':\n        sampler = ADASYN(random_state=random_state)\n\n    elif strategy == 'borderline_smote':\n        sampler = BorderlineSMOTE(random_state=random_state)\n\n    elif strategy == 'smote_tomek':\n        sampler = SMOTETomek(random_state=random_state)\n\n    elif strategy == 'smote_enn':\n        sampler = SMOTEENN(random_state=random_state)\n\n    elif strategy == 'random_undersample':\n        sampler = RandomUnderSampler(random_state=random_state)\n\n    else:\n        raise ValueError(f\"Unknown sampling strategy: {strategy}\")\n\n    X_resampled, y_resampled = sampler.fit_resample(X, y)\n\n    print(f\"Original distribution: {Counter(y)}\")\n    print(f\"Resampled distribution: {Counter(y_resampled)}\")\n\n    return X_resampled, y_resampled\n\n# Test different sampling strategies\nsampling_strategies = ['none', 'smote', 'adasyn', 'borderline_smote', 'smote_tomek']\n\nprint(\"Available sampling strategies:\", sampling_strategies)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"M-1uUaSSQDlA","outputId":"f86abf9c-862b-4c44-b951-7481ce66d05e","trusted":true,"execution":{"iopub.status.busy":"2025-07-26T06:20:51.593639Z","iopub.execute_input":"2025-07-26T06:20:51.593918Z","iopub.status.idle":"2025-07-26T06:20:51.600991Z","shell.execute_reply.started":"2025-07-26T06:20:51.593891Z","shell.execute_reply":"2025-07-26T06:20:51.600228Z"}},"outputs":[{"name":"stdout","text":"Available sampling strategies: ['none', 'smote', 'adasyn', 'borderline_smote', 'smote_tomek']\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"## 3. Model Definitions","metadata":{"id":"hY0Q6vEbQDlA"}},{"cell_type":"code","source":"def get_models(class_weight='balanced'):\n    \"\"\"Get dictionary of models with appropriate class weights\"\"\"\n\n    models = {\n        'Logistic Regression': LogisticRegression(\n            class_weight=class_weight,\n            random_state=42,\n            max_iter=1000\n        ),\n\n        'Random Forest': RandomForestClassifier(\n            class_weight=class_weight,\n            random_state=42,\n            n_estimators=100\n        ),\n\n        'Balanced Random Forest': BalancedRandomForestClassifier(\n            random_state=42,\n            n_estimators=100\n        ),\n\n        'XGBoost': xgb.XGBClassifier(\n            random_state=42,\n            eval_metric='logloss',\n            use_label_encoder=False\n        ),\n\n        'LightGBM': lgb.LGBMClassifier(\n            random_state=42,\n            class_weight=class_weight,\n            verbose=-1\n        ),\n\n        'Gradient Boosting': GradientBoostingClassifier(\n            random_state=42\n        )\n    }\n\n    return models\n\nprint(\"Model definitions created\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WBwAsdRyQDlA","outputId":"149b698c-42bf-493a-9d1e-19fb52cb0d4e","trusted":true,"execution":{"iopub.status.busy":"2025-07-26T06:20:51.601707Z","iopub.execute_input":"2025-07-26T06:20:51.601960Z","iopub.status.idle":"2025-07-26T06:20:51.622616Z","shell.execute_reply.started":"2025-07-26T06:20:51.601944Z","shell.execute_reply":"2025-07-26T06:20:51.621969Z"}},"outputs":[{"name":"stdout","text":"Model definitions created\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"def evaluate_model(model, X_test, y_test, model_name='Model'):\n    \"\"\"Comprehensive model evaluation\"\"\"\n\n    # Predictions\n    y_pred = model.predict(X_test)\n    y_pred_proba = model.predict_proba(X_test)[:, 1] if hasattr(model, 'predict_proba') else None\n\n    # Calculate metrics\n    precision = precision_score(y_test, y_pred)\n    recall = recall_score(y_test, y_pred)\n    f1 = f1_score(y_test, y_pred)\n\n    if y_pred_proba is not None:\n        roc_auc = roc_auc_score(y_test, y_pred_proba)\n        pr_auc = average_precision_score(y_test, y_pred_proba)\n    else:\n        roc_auc = None\n        pr_auc = None\n\n    results = {\n        'Model': model_name,\n        'Precision': precision,\n        'Recall': recall,\n        'F1-Score': f1,\n        'ROC-AUC': roc_auc,\n        'PR-AUC': pr_auc\n    }\n\n    return results, y_pred, y_pred_proba\n\nprint(\"Evaluation function defined\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RmtyK5frQDlB","outputId":"139601f9-8623-4370-9337-4850dd11924c","trusted":true,"execution":{"iopub.status.busy":"2025-07-26T06:20:51.623421Z","iopub.execute_input":"2025-07-26T06:20:51.623829Z","iopub.status.idle":"2025-07-26T06:20:51.643559Z","shell.execute_reply.started":"2025-07-26T06:20:51.623803Z","shell.execute_reply":"2025-07-26T06:20:51.642903Z"}},"outputs":[{"name":"stdout","text":"Evaluation function defined\n","output_type":"stream"}],"execution_count":8},{"cell_type":"markdown","source":"## 4. Model Training - Fraud Data (E-commerce)","metadata":{"id":"2z0p1xfAQDlB"}},{"cell_type":"code","source":"fraud_results = []\nfraud_models = {}\n\nprint(\"Training models on E-commerce Fraud Data...\")\nprint(\"=\" * 50)\n\n# Test different sampling strategies\nbest_sampling_strategies = ['none', 'smote', 'borderline_smote']\n\nfor sampling_strategy in best_sampling_strategies:\n    print(f\"\\n--- Sampling Strategy: {sampling_strategy.upper()} ---\")\n\n    # Apply sampling\n    X_fraud_resampled, y_fraud_resampled = apply_sampling_strategy(\n        X_fraud_train, y_fraud_train, strategy=sampling_strategy\n    )\n\n    # Get models\n    models = get_models()\n\n    for model_name, model in models.items():\n        print(f\"\\nTraining {model_name}...\")\n\n        try:\n            # Train model\n            model.fit(X_fraud_resampled, y_fraud_resampled)\n\n            # Evaluate\n            results, y_pred, y_pred_proba = evaluate_model(\n                model, X_fraud_test, y_fraud_test,\n                f\"{model_name} ({sampling_strategy})\"\n            )\n\n            results['Sampling'] = sampling_strategy\n            fraud_results.append(results)\n\n            # Store best models\n            key = f\"{model_name}_{sampling_strategy}\"\n            fraud_models[key] = model\n\n            print(f\"F1-Score: {results['F1-Score']:.4f}, Precision: {results['Precision']:.4f}, Recall: {results['Recall']:.4f}\")\n\n        except Exception as e:\n            print(f\"Error training {model_name}: {str(e)}\")\n            continue\n\nprint(\"\\nFraud data model training completed!\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DASlJofvQDlB","outputId":"64d60b58-9db0-451a-9390-1d232264b976","trusted":true,"execution":{"iopub.status.busy":"2025-07-26T06:20:51.644289Z","iopub.execute_input":"2025-07-26T06:20:51.644498Z","iopub.status.idle":"2025-07-26T06:31:35.646834Z","shell.execute_reply.started":"2025-07-26T06:20:51.644483Z","shell.execute_reply":"2025-07-26T06:31:35.646082Z"}},"outputs":[{"name":"stdout","text":"Training models on E-commerce Fraud Data...\n==================================================\n\n--- Sampling Strategy: NONE ---\n\nTraining Logistic Regression...\nF1-Score: 0.9113, Precision: 0.8406, Recall: 0.9951\n\nTraining Random Forest...\nF1-Score: 0.9272, Precision: 0.9695, Recall: 0.8883\n\nTraining Balanced Random Forest...\nF1-Score: 0.9111, Precision: 0.8368, Recall: 1.0000\n\nTraining XGBoost...\nF1-Score: 0.9304, Precision: 0.9322, Recall: 0.9286\n\nTraining LightGBM...\n","output_type":"stream"},{"name":"stderr","text":"[LightGBM] [Fatal] Do not support special JSON characters in feature name.\n","output_type":"stream"},{"name":"stdout","text":"Error training LightGBM: Do not support special JSON characters in feature name.\n\nTraining Gradient Boosting...\nF1-Score: 0.9338, Precision: 0.9765, Recall: 0.8947\n\n--- Sampling Strategy: SMOTE ---\nOriginal distribution: Counter({0: 109568, 1: 11321})\nResampled distribution: Counter({0: 109568, 1: 109568})\n\nTraining Logistic Regression...\nF1-Score: 0.9099, Precision: 0.8426, Recall: 0.9890\n\nTraining Random Forest...\nF1-Score: 0.9125, Precision: 0.8817, Recall: 0.9456\n\nTraining Balanced Random Forest...\nF1-Score: 0.9146, Precision: 0.8816, Recall: 0.9502\n\nTraining XGBoost...\nF1-Score: 0.9295, Precision: 0.9300, Recall: 0.9290\n\nTraining LightGBM...\n","output_type":"stream"},{"name":"stderr","text":"[LightGBM] [Fatal] Do not support special JSON characters in feature name.\n","output_type":"stream"},{"name":"stdout","text":"Error training LightGBM: Do not support special JSON characters in feature name.\n\nTraining Gradient Boosting...\nF1-Score: 0.9244, Precision: 0.8672, Recall: 0.9898\n\n--- Sampling Strategy: BORDERLINE_SMOTE ---\nOriginal distribution: Counter({0: 109568, 1: 11321})\nResampled distribution: Counter({0: 109568, 1: 109568})\n\nTraining Logistic Regression...\nF1-Score: 0.9109, Precision: 0.8413, Recall: 0.9929\n\nTraining Random Forest...\nF1-Score: 0.9139, Precision: 0.8867, Recall: 0.9428\n\nTraining Balanced Random Forest...\nF1-Score: 0.9102, Precision: 0.8820, Recall: 0.9403\n\nTraining XGBoost...\nF1-Score: 0.9283, Precision: 0.9237, Recall: 0.9329\n\nTraining LightGBM...\n","output_type":"stream"},{"name":"stderr","text":"[LightGBM] [Fatal] Do not support special JSON characters in feature name.\n","output_type":"stream"},{"name":"stdout","text":"Error training LightGBM: Do not support special JSON characters in feature name.\n\nTraining Gradient Boosting...\nF1-Score: 0.9223, Precision: 0.8630, Recall: 0.9905\n\nFraud data model training completed!\n","output_type":"stream"}],"execution_count":9},{"cell_type":"markdown","source":"## Display fraud data results","metadata":{"id":"Ay79FZhdQDlB"}},{"cell_type":"code","source":"fraud_results_df = pd.DataFrame(fraud_results)\nfraud_results_df = fraud_results_df.sort_values('F1-Score', ascending=False)\n\nprint(\"E-COMMERCE FRAUD DETECTION RESULTS:\")\nprint(\"=\" * 60)\nprint(fraud_results_df.round(4))\n\n# Best model for fraud data\nbest_fraud_model = fraud_results_df.iloc[0]\nprint(f\"\\nBest Model for E-commerce Fraud: {best_fraud_model['Model']}\")\nprint(f\"F1-Score: {best_fraud_model['F1-Score']:.4f}\")\nprint(f\"Precision: {best_fraud_model['Precision']:.4f}\")\nprint(f\"Recall: {best_fraud_model['Recall']:.4f}\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"s4n3lW3VQDlC","outputId":"15962b95-9f94-4aea-fab7-214a110c4ba0","trusted":true,"execution":{"iopub.status.busy":"2025-07-26T06:31:35.647685Z","iopub.execute_input":"2025-07-26T06:31:35.648102Z","iopub.status.idle":"2025-07-26T06:31:35.659089Z","shell.execute_reply.started":"2025-07-26T06:31:35.648073Z","shell.execute_reply":"2025-07-26T06:31:35.658379Z"}},"outputs":[{"name":"stdout","text":"E-COMMERCE FRAUD DETECTION RESULTS:\n============================================================\n                                        Model  Precision  Recall  F1-Score  \\\n4                    Gradient Boosting (none)     0.9765  0.8947    0.9338   \n3                              XGBoost (none)     0.9322  0.9286    0.9304   \n8                             XGBoost (smote)     0.9300  0.9290    0.9295   \n13                 XGBoost (borderline_smote)     0.9237  0.9329    0.9283   \n1                        Random Forest (none)     0.9695  0.8883    0.9272   \n9                   Gradient Boosting (smote)     0.8672  0.9898    0.9244   \n14       Gradient Boosting (borderline_smote)     0.8630  0.9905    0.9223   \n7              Balanced Random Forest (smote)     0.8816  0.9502    0.9146   \n11           Random Forest (borderline_smote)     0.8867  0.9428    0.9139   \n6                       Random Forest (smote)     0.8817  0.9456    0.9125   \n0                  Logistic Regression (none)     0.8406  0.9951    0.9113   \n2               Balanced Random Forest (none)     0.8368  1.0000    0.9111   \n10     Logistic Regression (borderline_smote)     0.8413  0.9929    0.9109   \n12  Balanced Random Forest (borderline_smote)     0.8820  0.9403    0.9102   \n5                 Logistic Regression (smote)     0.8426  0.9890    0.9099   \n\n    ROC-AUC  PR-AUC          Sampling  \n4    0.9991  0.9910              none  \n3    0.9990  0.9905              none  \n8    0.9973  0.9884             smote  \n13   0.9974  0.9882  borderline_smote  \n1    0.9988  0.9889              none  \n9    0.9988  0.9892             smote  \n14   0.9988  0.9888  borderline_smote  \n7    0.9980  0.9797             smote  \n11   0.9980  0.9797  borderline_smote  \n6    0.9979  0.9787             smote  \n0    0.9982  0.9833              none  \n2    0.9976  0.9741              none  \n10   0.9981  0.9828  borderline_smote  \n12   0.9978  0.9773  borderline_smote  \n5    0.9982  0.9832             smote  \n\nBest Model for E-commerce Fraud: Gradient Boosting (none)\nF1-Score: 0.9338\nPrecision: 0.9765\nRecall: 0.8947\n","output_type":"stream"}],"execution_count":10},{"cell_type":"markdown","source":"## 5. Model Training - Credit Card Data","metadata":{"id":"AKq49I4YQDlC"}},{"cell_type":"code","source":"cc_results = []\ncc_models = {}\n\nprint(\"Training models on Credit Card Data...\")\nprint(\"=\" * 50)\n\n# Test different sampling strategies\nfor sampling_strategy in best_sampling_strategies:\n    print(f\"\\n--- Sampling Strategy: {sampling_strategy.upper()} ---\")\n\n    # Apply sampling\n    X_cc_resampled, y_cc_resampled = apply_sampling_strategy(\n        X_cc_train, y_cc_train, strategy=sampling_strategy\n    )\n\n    # Get models\n    models = get_models()\n\n    for model_name, model in models.items():\n        print(f\"\\nTraining {model_name}...\")\n\n        try:\n            # Train model\n            model.fit(X_cc_resampled, y_cc_resampled)\n\n            # Evaluate\n            results, y_pred, y_pred_proba = evaluate_model(\n                model, X_cc_test, y_cc_test,\n                f\"{model_name} ({sampling_strategy})\"\n            )\n\n            results['Sampling'] = sampling_strategy\n            cc_results.append(results)\n\n            # Store best models\n            key = f\"{model_name}_{sampling_strategy}\"\n            cc_models[key] = model\n\n            print(f\"F1-Score: {results['F1-Score']:.4f}, Precision: {results['Precision']:.4f}, Recall: {results['Recall']:.4f}\")\n\n        except Exception as e:\n            print(f\"Error training {model_name}: {str(e)}\")\n            continue\n\nprint(\"\\nCredit card data model training completed!\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z5ih0gRTQDlC","outputId":"0cd7e0d0-0dac-4e46-f453-bf68cd5fa0ba","trusted":true,"execution":{"iopub.status.busy":"2025-07-26T06:31:35.661211Z","iopub.execute_input":"2025-07-26T06:31:35.661481Z","iopub.status.idle":"2025-07-26T07:59:25.097862Z","shell.execute_reply.started":"2025-07-26T06:31:35.661464Z","shell.execute_reply":"2025-07-26T07:59:25.097181Z"}},"outputs":[{"name":"stdout","text":"Training models on Credit Card Data...\n==================================================\n\n--- Sampling Strategy: NONE ---\n\nTraining Logistic Regression...\nF1-Score: 0.0955, Precision: 0.0504, Recall: 0.9082\n\nTraining Random Forest...\nF1-Score: 0.8475, Precision: 0.9494, Recall: 0.7653\n\nTraining Balanced Random Forest...\nF1-Score: 0.1066, Precision: 0.0566, Recall: 0.9184\n\nTraining XGBoost...\nF1-Score: 0.8556, Precision: 0.8989, Recall: 0.8163\n\nTraining LightGBM...\nF1-Score: 0.8458, Precision: 0.8252, Recall: 0.8673\n\nTraining Gradient Boosting...\nF1-Score: 0.8066, Precision: 0.8795, Recall: 0.7449\n\n--- Sampling Strategy: SMOTE ---\nOriginal distribution: Counter({0: 227451, 1: 394})\nResampled distribution: Counter({0: 227451, 1: 227451})\n\nTraining Logistic Regression...\nF1-Score: 0.0926, Precision: 0.0488, Recall: 0.9082\n\nTraining Random Forest...\nF1-Score: 0.8646, Precision: 0.8830, Recall: 0.8469\n\nTraining Balanced Random Forest...\nF1-Score: 0.8571, Precision: 0.8901, Recall: 0.8265\n\nTraining XGBoost...\nF1-Score: 0.8513, Precision: 0.8557, Recall: 0.8469\n\nTraining LightGBM...\nF1-Score: 0.7941, Precision: 0.7642, Recall: 0.8265\n\nTraining Gradient Boosting...\nF1-Score: 0.2876, Precision: 0.1708, Recall: 0.9082\n\n--- Sampling Strategy: BORDERLINE_SMOTE ---\nOriginal distribution: Counter({0: 227451, 1: 394})\nResampled distribution: Counter({0: 227451, 1: 227451})\n\nTraining Logistic Regression...\nF1-Score: 0.4327, Precision: 0.2918, Recall: 0.8367\n\nTraining Random Forest...\nF1-Score: 0.8508, Precision: 0.9277, Recall: 0.7857\n\nTraining Balanced Random Forest...\nF1-Score: 0.8398, Precision: 0.9157, Recall: 0.7755\n\nTraining XGBoost...\nF1-Score: 0.8513, Precision: 0.8557, Recall: 0.8469\n\nTraining LightGBM...\nF1-Score: 0.8039, Precision: 0.7736, Recall: 0.8367\n\nTraining Gradient Boosting...\nF1-Score: 0.5483, Precision: 0.3946, Recall: 0.8980\n\nCredit card data model training completed!\n","output_type":"stream"}],"execution_count":11},{"cell_type":"markdown","source":"## Display credit card results","metadata":{"id":"16V82OpOQDlC"}},{"cell_type":"code","source":"cc_results_df = pd.DataFrame(cc_results)\ncc_results_df = cc_results_df.sort_values('F1-Score', ascending=False)\n\nprint(\"CREDIT CARD FRAUD DETECTION RESULTS:\")\nprint(\"=\" * 60)\nprint(cc_results_df.round(4))\n\n# Best model for credit card data\nbest_cc_model = cc_results_df.iloc[0]\nprint(f\"\\nBest Model for Credit Card Fraud: {best_cc_model['Model']}\")\nprint(f\"F1-Score: {best_cc_model['F1-Score']:.4f}\")\nprint(f\"Precision: {best_cc_model['Precision']:.4f}\")\nprint(f\"Recall: {best_cc_model['Recall']:.4f}\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KlURULL8QDlD","outputId":"892a8a41-edbd-41fc-fa22-c0d942064b7e","trusted":true,"execution":{"iopub.status.busy":"2025-07-26T07:59:25.098570Z","iopub.execute_input":"2025-07-26T07:59:25.098877Z","iopub.status.idle":"2025-07-26T07:59:25.108684Z","shell.execute_reply.started":"2025-07-26T07:59:25.098858Z","shell.execute_reply":"2025-07-26T07:59:25.108090Z"}},"outputs":[{"name":"stdout","text":"CREDIT CARD FRAUD DETECTION RESULTS:\n============================================================\n                                        Model  Precision  Recall  F1-Score  \\\n7                       Random Forest (smote)     0.8830  0.8469    0.8646   \n8              Balanced Random Forest (smote)     0.8901  0.8265    0.8571   \n3                              XGBoost (none)     0.8989  0.8163    0.8556   \n9                             XGBoost (smote)     0.8557  0.8469    0.8513   \n15                 XGBoost (borderline_smote)     0.8557  0.8469    0.8513   \n13           Random Forest (borderline_smote)     0.9277  0.7857    0.8508   \n1                        Random Forest (none)     0.9494  0.7653    0.8475   \n4                             LightGBM (none)     0.8252  0.8673    0.8458   \n14  Balanced Random Forest (borderline_smote)     0.9157  0.7755    0.8398   \n5                    Gradient Boosting (none)     0.8795  0.7449    0.8066   \n16                LightGBM (borderline_smote)     0.7736  0.8367    0.8039   \n10                           LightGBM (smote)     0.7642  0.8265    0.7941   \n17       Gradient Boosting (borderline_smote)     0.3946  0.8980    0.5483   \n12     Logistic Regression (borderline_smote)     0.2918  0.8367    0.4327   \n11                  Gradient Boosting (smote)     0.1708  0.9082    0.2876   \n2               Balanced Random Forest (none)     0.0566  0.9184    0.1066   \n0                  Logistic Regression (none)     0.0504  0.9082    0.0955   \n6                 Logistic Regression (smote)     0.0488  0.9082    0.0926   \n\n    ROC-AUC  PR-AUC          Sampling  \n7    0.9684  0.8809             smote  \n8    0.9687  0.8803             smote  \n3    0.9605  0.7519              none  \n9    0.9807  0.8793             smote  \n15   0.9715  0.8706  borderline_smote  \n13   0.9577  0.8759  borderline_smote  \n1    0.9530  0.8732              none  \n4    0.9630  0.8789              none  \n14   0.9628  0.8765  borderline_smote  \n5    0.8448  0.6843              none  \n16   0.9735  0.7690  borderline_smote  \n10   0.9400  0.7798             smote  \n17   0.9733  0.7886  borderline_smote  \n12   0.9632  0.7357  borderline_smote  \n11   0.9839  0.8354             smote  \n2    0.9742  0.7428              none  \n0    0.9723  0.7473              none  \n6    0.9725  0.7243             smote  \n\nBest Model for Credit Card Fraud: Random Forest (smote)\nF1-Score: 0.8646\nPrecision: 0.8830\nRecall: 0.8469\n","output_type":"stream"}],"execution_count":12},{"cell_type":"markdown","source":"## 6. Hyperparameter Optimization","metadata":{"id":"p4VmGmuUQDlD"}},{"cell_type":"code","source":"def optimize_model(model_class, param_grid, X_train, y_train, cv=3, scoring='f1'):\n    \"\"\"Optimize hyperparameters using GridSearchCV\"\"\"\n\n    grid_search = GridSearchCV(\n        model_class,\n        param_grid,\n        cv=StratifiedKFold(n_splits=cv, shuffle=True, random_state=42),\n        scoring=scoring,\n        n_jobs=-1,\n        verbose=1\n    )\n\n    grid_search.fit(X_train, y_train)\n\n    return grid_search.best_estimator_, grid_search.best_params_, grid_search.best_score_\n\n# Define parameter grids for top models\nparam_grids = {\n    'RandomForestClassifier': {\n        'n_estimators': [100, 200],\n        'max_depth': [10, 20, None],\n        'min_samples_split': [2, 5],\n        'min_samples_leaf': [1, 2]\n    },\n\n    'XGBClassifier': {\n        'n_estimators': [100, 200],\n        'max_depth': [3, 6, 9],\n        'learning_rate': [0.01, 0.1, 0.2],\n        'subsample': [0.8, 1.0]\n    },\n\n    'LGBMClassifier': {\n        'n_estimators': [100, 200],\n        'max_depth': [3, 6, 9],\n        'learning_rate': [0.01, 0.1, 0.2],\n        'num_leaves': [31, 50, 100]\n    }\n}\n\nprint(\"Hyperparameter optimization setup completed\")","metadata":{"id":"rwKEWCXaQDlD","colab":{"base_uri":"https://localhost:8080/"},"outputId":"f16cdaaf-ecb9-4ce9-a03f-a35b5d5dc497","trusted":true,"execution":{"iopub.status.busy":"2025-07-26T07:59:25.109627Z","iopub.execute_input":"2025-07-26T07:59:25.109875Z","iopub.status.idle":"2025-07-26T07:59:25.130250Z","shell.execute_reply.started":"2025-07-26T07:59:25.109851Z","shell.execute_reply":"2025-07-26T07:59:25.129704Z"}},"outputs":[{"name":"stdout","text":"Hyperparameter optimization setup completed\n","output_type":"stream"}],"execution_count":13},{"cell_type":"markdown","source":"## Optimize best models for fraud data","metadata":{"id":"ftizdtR7QDlD"}},{"cell_type":"code","source":"print(\"Optimizing models for E-commerce Fraud Data...\")\n# Use SMOTE for optimization (generally performs well)\nX_fraud_smote, y_fraud_smote = apply_sampling_strategy(X_fraud_train, y_fraud_train, 'smote')\noptimized_fraud_models = {}\n# Optimize Random Forest\nprint(\"\\nOptimizing Random Forest...\")\nrf_optimized, rf_best_params, rf_best_score = optimize_model(\n    RandomForestClassifier(class_weight='balanced', random_state=42),\n    param_grids['RandomForestClassifier'],\n    X_fraud_smote, y_fraud_smote\n)\noptimized_fraud_models['Random Forest'] = rf_optimized\nprint(f\"Best RF params: {rf_best_params}\")\nprint(f\"Best RF score: {rf_best_score:.4f}\")\n\n# Optimize XGBoost\nprint(\"\\nOptimizing XGBoost...\")\nxgb_optimized, xgb_best_params, xgb_best_score = optimize_model(\n    xgb.XGBClassifier(random_state=42, eval_metric='logloss', use_label_encoder=False),\n    param_grids['XGBClassifier'],\n    X_fraud_smote, y_fraud_smote\n)\noptimized_fraud_models['XGBoost'] = xgb_optimized\nprint(f\"Best XGB params: {xgb_best_params}\")\nprint(f\"Best XGB score: {xgb_best_score:.4f}\")","metadata":{"id":"in6dDLbEQDlD","colab":{"base_uri":"https://localhost:8080/"},"outputId":"45be8f1f-ff47-45b7-c414-4450ecf3ffc5","trusted":true,"execution":{"iopub.status.busy":"2025-07-26T07:59:25.130825Z","iopub.execute_input":"2025-07-26T07:59:25.130993Z","iopub.status.idle":"2025-07-26T08:25:05.863537Z","shell.execute_reply.started":"2025-07-26T07:59:25.130979Z","shell.execute_reply":"2025-07-26T08:25:05.862738Z"}},"outputs":[{"name":"stdout","text":"Optimizing models for E-commerce Fraud Data...\nOriginal distribution: Counter({0: 109568, 1: 11321})\nResampled distribution: Counter({0: 109568, 1: 109568})\n\nOptimizing Random Forest...\nFitting 3 folds for each of 24 candidates, totalling 72 fits\nBest RF params: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\nBest RF score: 0.9922\n\nOptimizing XGBoost...\nFitting 3 folds for each of 36 candidates, totalling 108 fits\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [08:14:31] WARNING: /workspace/src/learner.cc:738: \nParameters: { \"use_label_encoder\" } are not used.\n\n  bst.update(dtrain, iteration=i, fobj=obj)\n/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [08:14:31] WARNING: /workspace/src/learner.cc:738: \nParameters: { \"use_label_encoder\" } are not used.\n\n  bst.update(dtrain, iteration=i, fobj=obj)\n/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [08:14:32] WARNING: /workspace/src/learner.cc:738: \nParameters: { \"use_label_encoder\" } are not used.\n\n  bst.update(dtrain, iteration=i, fobj=obj)\n/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [08:14:32] WARNING: /workspace/src/learner.cc:738: \nParameters: { \"use_label_encoder\" } are not used.\n\n  bst.update(dtrain, iteration=i, fobj=obj)\n/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [08:14:47] WARNING: /workspace/src/learner.cc:738: \nParameters: { \"use_label_encoder\" } are not used.\n\n  bst.update(dtrain, iteration=i, fobj=obj)\n/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [08:14:48] WARNING: /workspace/src/learner.cc:738: \nParameters: { \"use_label_encoder\" } are not used.\n\n  bst.update(dtrain, iteration=i, fobj=obj)\n/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [08:14:48] WARNING: /workspace/src/learner.cc:738: \nParameters: { \"use_label_encoder\" } are not used.\n\n  bst.update(dtrain, iteration=i, fobj=obj)\n/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [08:14:48] WARNING: /workspace/src/learner.cc:738: \nParameters: { \"use_label_encoder\" } are not used.\n\n  bst.update(dtrain, iteration=i, fobj=obj)\n/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [08:15:00] WARNING: /workspace/src/learner.cc:738: \nParameters: { \"use_label_encoder\" } are not used.\n\n  bst.update(dtrain, iteration=i, fobj=obj)\n/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [08:15:01] WARNING: /workspace/src/learner.cc:738: \nParameters: { \"use_label_encoder\" } are not used.\n\n  bst.update(dtrain, iteration=i, fobj=obj)\n/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [08:15:09] WARNING: /workspace/src/learner.cc:738: \nParameters: { \"use_label_encoder\" } are not used.\n\n  bst.update(dtrain, iteration=i, fobj=obj)\n/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [08:15:09] WARNING: /workspace/src/learner.cc:738: \nParameters: { \"use_label_encoder\" } are not used.\n\n  bst.update(dtrain, iteration=i, fobj=obj)\n/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [08:15:23] WARNING: /workspace/src/learner.cc:738: \nParameters: { \"use_label_encoder\" } are not used.\n\n  bst.update(dtrain, iteration=i, fobj=obj)\n/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [08:15:24] WARNING: /workspace/src/learner.cc:738: \nParameters: { \"use_label_encoder\" } are not used.\n\n  bst.update(dtrain, iteration=i, fobj=obj)\n/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [08:15:32] WARNING: /workspace/src/learner.cc:738: \nParameters: { \"use_label_encoder\" } are not used.\n\n  bst.update(dtrain, iteration=i, fobj=obj)\n/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [08:15:32] WARNING: /workspace/src/learner.cc:738: \nParameters: { \"use_label_encoder\" } are not used.\n\n  bst.update(dtrain, iteration=i, fobj=obj)\n/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [08:15:38] WARNING: /workspace/src/learner.cc:738: \nParameters: { \"use_label_encoder\" } are not used.\n\n  bst.update(dtrain, iteration=i, fobj=obj)\n/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [08:15:39] WARNING: /workspace/src/learner.cc:738: \nParameters: { \"use_label_encoder\" } are not used.\n\n  bst.update(dtrain, iteration=i, fobj=obj)\n/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [08:15:47] WARNING: /workspace/src/learner.cc:738: \nParameters: { \"use_label_encoder\" } are not used.\n\n  bst.update(dtrain, iteration=i, fobj=obj)\n/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [08:15:48] WARNING: /workspace/src/learner.cc:738: \nParameters: { \"use_label_encoder\" } are not used.\n\n  bst.update(dtrain, iteration=i, fobj=obj)\n/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [08:15:54] WARNING: /workspace/src/learner.cc:738: \nParameters: { \"use_label_encoder\" } are not used.\n\n  bst.update(dtrain, iteration=i, fobj=obj)\n/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [08:15:57] WARNING: /workspace/src/learner.cc:738: \nParameters: { \"use_label_encoder\" } are not used.\n\n  bst.update(dtrain, iteration=i, fobj=obj)\n/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [08:16:16] WARNING: /workspace/src/learner.cc:738: \nParameters: { \"use_label_encoder\" } are not used.\n\n  bst.update(dtrain, iteration=i, fobj=obj)\n/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [08:16:16] WARNING: /workspace/src/learner.cc:738: \nParameters: { \"use_label_encoder\" } are not used.\n\n  bst.update(dtrain, iteration=i, fobj=obj)\n/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [08:16:23] WARNING: /workspace/src/learner.cc:738: \nParameters: { \"use_label_encoder\" } are not used.\n\n  bst.update(dtrain, iteration=i, fobj=obj)\n/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [08:16:24] WARNING: /workspace/src/learner.cc:738: \nParameters: { \"use_label_encoder\" } are not used.\n\n  bst.update(dtrain, iteration=i, fobj=obj)\n/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [08:16:41] WARNING: /workspace/src/learner.cc:738: \nParameters: { \"use_label_encoder\" } are not used.\n\n  bst.update(dtrain, iteration=i, fobj=obj)\n/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [08:16:42] WARNING: /workspace/src/learner.cc:738: \nParameters: { \"use_label_encoder\" } are not used.\n\n  bst.update(dtrain, iteration=i, fobj=obj)\n/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [08:16:42] WARNING: /workspace/src/learner.cc:738: \nParameters: { \"use_label_encoder\" } are not used.\n\n  bst.update(dtrain, iteration=i, fobj=obj)\n/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [08:16:43] WARNING: /workspace/src/learner.cc:738: \nParameters: { \"use_label_encoder\" } are not used.\n\n  bst.update(dtrain, iteration=i, fobj=obj)\n/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [08:16:59] WARNING: /workspace/src/learner.cc:738: \nParameters: { \"use_label_encoder\" } are not used.\n\n  bst.update(dtrain, iteration=i, fobj=obj)\n/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [08:17:00] WARNING: /workspace/src/learner.cc:738: \nParameters: { \"use_label_encoder\" } are not used.\n\n  bst.update(dtrain, iteration=i, fobj=obj)\n/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [08:17:01] WARNING: /workspace/src/learner.cc:738: \nParameters: { \"use_label_encoder\" } are not used.\n\n  bst.update(dtrain, iteration=i, fobj=obj)\n/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [08:17:03] WARNING: /workspace/src/learner.cc:738: \nParameters: { \"use_label_encoder\" } are not used.\n\n  bst.update(dtrain, iteration=i, fobj=obj)\n/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [08:17:31] WARNING: /workspace/src/learner.cc:738: \nParameters: { \"use_label_encoder\" } are not used.\n\n  bst.update(dtrain, iteration=i, fobj=obj)\n/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [08:17:32] WARNING: /workspace/src/learner.cc:738: \nParameters: { \"use_label_encoder\" } are not used.\n\n  bst.update(dtrain, iteration=i, fobj=obj)\n/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [08:17:35] WARNING: /workspace/src/learner.cc:738: \nParameters: { \"use_label_encoder\" } are not used.\n\n  bst.update(dtrain, iteration=i, fobj=obj)\n/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [08:17:36] WARNING: /workspace/src/learner.cc:738: \nParameters: { \"use_label_encoder\" } are not used.\n\n  bst.update(dtrain, iteration=i, fobj=obj)\n/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [08:17:48] WARNING: /workspace/src/learner.cc:738: \nParameters: { \"use_label_encoder\" } are not used.\n\n  bst.update(dtrain, iteration=i, fobj=obj)\n/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [08:17:50] WARNING: /workspace/src/learner.cc:738: \nParameters: { \"use_label_encoder\" } are not used.\n\n  bst.update(dtrain, iteration=i, fobj=obj)\n/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [08:18:02] WARNING: /workspace/src/learner.cc:738: \nParameters: { \"use_label_encoder\" } are not used.\n\n  bst.update(dtrain, iteration=i, fobj=obj)\n/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [08:18:04] WARNING: /workspace/src/learner.cc:738: \nParameters: { \"use_label_encoder\" } are not used.\n\n  bst.update(dtrain, iteration=i, fobj=obj)\n/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [08:18:04] WARNING: /workspace/src/learner.cc:738: \nParameters: { \"use_label_encoder\" } are not used.\n\n  bst.update(dtrain, iteration=i, fobj=obj)\n/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [08:18:04] WARNING: /workspace/src/learner.cc:738: \nParameters: { \"use_label_encoder\" } are not used.\n\n  bst.update(dtrain, iteration=i, fobj=obj)\n/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [08:18:15] WARNING: /workspace/src/learner.cc:738: \nParameters: { \"use_label_encoder\" } are not used.\n\n  bst.update(dtrain, iteration=i, fobj=obj)\n/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [08:18:16] WARNING: /workspace/src/learner.cc:738: \nParameters: { \"use_label_encoder\" } are not used.\n\n  bst.update(dtrain, iteration=i, fobj=obj)\n/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [08:18:25] WARNING: /workspace/src/learner.cc:738: \nParameters: { \"use_label_encoder\" } are not used.\n\n  bst.update(dtrain, iteration=i, fobj=obj)\n/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [08:18:25] WARNING: /workspace/src/learner.cc:738: \nParameters: { \"use_label_encoder\" } are not used.\n\n  bst.update(dtrain, iteration=i, fobj=obj)\n/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [08:18:36] WARNING: /workspace/src/learner.cc:738: \nParameters: { \"use_label_encoder\" } are not used.\n\n  bst.update(dtrain, iteration=i, fobj=obj)\n/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [08:18:39] WARNING: /workspace/src/learner.cc:738: \nParameters: { \"use_label_encoder\" } are not used.\n\n  bst.update(dtrain, iteration=i, fobj=obj)\n/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [08:18:46] WARNING: /workspace/src/learner.cc:738: \nParameters: { \"use_label_encoder\" } are not used.\n\n  bst.update(dtrain, iteration=i, fobj=obj)\n/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [08:18:47] WARNING: /workspace/src/learner.cc:738: \nParameters: { \"use_label_encoder\" } are not used.\n\n  bst.update(dtrain, iteration=i, fobj=obj)\n/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [08:18:52] WARNING: /workspace/src/learner.cc:738: \nParameters: { \"use_label_encoder\" } are not used.\n\n  bst.update(dtrain, iteration=i, fobj=obj)\n/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [08:18:55] WARNING: /workspace/src/learner.cc:738: \nParameters: { \"use_label_encoder\" } are not used.\n\n  bst.update(dtrain, iteration=i, fobj=obj)\n/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [08:19:03] WARNING: /workspace/src/learner.cc:738: \nParameters: { \"use_label_encoder\" } are not used.\n\n  bst.update(dtrain, iteration=i, fobj=obj)\n/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [08:19:04] WARNING: /workspace/src/learner.cc:738: \nParameters: { \"use_label_encoder\" } are not used.\n\n  bst.update(dtrain, iteration=i, fobj=obj)\n/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [08:19:08] WARNING: /workspace/src/learner.cc:738: \nParameters: { \"use_label_encoder\" } are not used.\n\n  bst.update(dtrain, iteration=i, fobj=obj)\n/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [08:19:11] WARNING: /workspace/src/learner.cc:738: \nParameters: { \"use_label_encoder\" } are not used.\n\n  bst.update(dtrain, iteration=i, fobj=obj)\n/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [08:19:32] WARNING: /workspace/src/learner.cc:738: \nParameters: { \"use_label_encoder\" } are not used.\n\n  bst.update(dtrain, iteration=i, fobj=obj)\n/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [08:19:36] WARNING: /workspace/src/learner.cc:738: \nParameters: { \"use_label_encoder\" } are not used.\n\n  bst.update(dtrain, iteration=i, fobj=obj)\n/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [08:19:38] WARNING: /workspace/src/learner.cc:738: \nParameters: { \"use_label_encoder\" } are not used.\n\n  bst.update(dtrain, iteration=i, fobj=obj)\n/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [08:19:41] WARNING: /workspace/src/learner.cc:738: \nParameters: { \"use_label_encoder\" } are not used.\n\n  bst.update(dtrain, iteration=i, fobj=obj)\n/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [08:19:58] WARNING: /workspace/src/learner.cc:738: \nParameters: { \"use_label_encoder\" } are not used.\n\n  bst.update(dtrain, iteration=i, fobj=obj)\n/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [08:20:01] WARNING: /workspace/src/learner.cc:738: \nParameters: { \"use_label_encoder\" } are not used.\n\n  bst.update(dtrain, iteration=i, fobj=obj)\n/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [08:20:02] WARNING: /workspace/src/learner.cc:738: \nParameters: { \"use_label_encoder\" } are not used.\n\n  bst.update(dtrain, iteration=i, fobj=obj)\n/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [08:20:04] WARNING: /workspace/src/learner.cc:738: \nParameters: { \"use_label_encoder\" } are not used.\n\n  bst.update(dtrain, iteration=i, fobj=obj)\n/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [08:20:18] WARNING: /workspace/src/learner.cc:738: \nParameters: { \"use_label_encoder\" } are not used.\n\n  bst.update(dtrain, iteration=i, fobj=obj)\n/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [08:20:21] WARNING: /workspace/src/learner.cc:738: \nParameters: { \"use_label_encoder\" } are not used.\n\n  bst.update(dtrain, iteration=i, fobj=obj)\n/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [08:20:23] WARNING: /workspace/src/learner.cc:738: \nParameters: { \"use_label_encoder\" } are not used.\n\n  bst.update(dtrain, iteration=i, fobj=obj)\n/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [08:20:25] WARNING: /workspace/src/learner.cc:738: \nParameters: { \"use_label_encoder\" } are not used.\n\n  bst.update(dtrain, iteration=i, fobj=obj)\n/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [08:20:56] WARNING: /workspace/src/learner.cc:738: \nParameters: { \"use_label_encoder\" } are not used.\n\n  bst.update(dtrain, iteration=i, fobj=obj)\n/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [08:21:00] WARNING: /workspace/src/learner.cc:738: \nParameters: { \"use_label_encoder\" } are not used.\n\n  bst.update(dtrain, iteration=i, fobj=obj)\n/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [08:21:01] WARNING: /workspace/src/learner.cc:738: \nParameters: { \"use_label_encoder\" } are not used.\n\n  bst.update(dtrain, iteration=i, fobj=obj)\n/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [08:21:02] WARNING: /workspace/src/learner.cc:738: \nParameters: { \"use_label_encoder\" } are not used.\n\n  bst.update(dtrain, iteration=i, fobj=obj)\n/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [08:21:14] WARNING: /workspace/src/learner.cc:738: \nParameters: { \"use_label_encoder\" } are not used.\n\n  bst.update(dtrain, iteration=i, fobj=obj)\n/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [08:21:15] WARNING: /workspace/src/learner.cc:738: \nParameters: { \"use_label_encoder\" } are not used.\n\n  bst.update(dtrain, iteration=i, fobj=obj)\n/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [08:21:27] WARNING: /workspace/src/learner.cc:738: \nParameters: { \"use_label_encoder\" } are not used.\n\n  bst.update(dtrain, iteration=i, fobj=obj)\n/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [08:21:28] WARNING: /workspace/src/learner.cc:738: \nParameters: { \"use_label_encoder\" } are not used.\n\n  bst.update(dtrain, iteration=i, fobj=obj)\n/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [08:21:33] WARNING: /workspace/src/learner.cc:738: \nParameters: { \"use_label_encoder\" } are not used.\n\n  bst.update(dtrain, iteration=i, fobj=obj)\n/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [08:21:38] WARNING: /workspace/src/learner.cc:738: \nParameters: { \"use_label_encoder\" } are not used.\n\n  bst.update(dtrain, iteration=i, fobj=obj)\n/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [08:21:40] WARNING: /workspace/src/learner.cc:738: \nParameters: { \"use_label_encoder\" } are not used.\n\n  bst.update(dtrain, iteration=i, fobj=obj)\n/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [08:21:41] WARNING: /workspace/src/learner.cc:738: \nParameters: { \"use_label_encoder\" } are not used.\n\n  bst.update(dtrain, iteration=i, fobj=obj)\n/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [08:21:53] WARNING: /workspace/src/learner.cc:738: \nParameters: { \"use_label_encoder\" } are not used.\n\n  bst.update(dtrain, iteration=i, fobj=obj)\n/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [08:21:59] WARNING: /workspace/src/learner.cc:738: \nParameters: { \"use_label_encoder\" } are not used.\n\n  bst.update(dtrain, iteration=i, fobj=obj)\n/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [08:22:01] WARNING: /workspace/src/learner.cc:738: \nParameters: { \"use_label_encoder\" } are not used.\n\n  bst.update(dtrain, iteration=i, fobj=obj)\n/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [08:22:01] WARNING: /workspace/src/learner.cc:738: \nParameters: { \"use_label_encoder\" } are not used.\n\n  bst.update(dtrain, iteration=i, fobj=obj)\n/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [08:22:12] WARNING: /workspace/src/learner.cc:738: \nParameters: { \"use_label_encoder\" } are not used.\n\n  bst.update(dtrain, iteration=i, fobj=obj)\n/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [08:22:18] WARNING: /workspace/src/learner.cc:738: \nParameters: { \"use_label_encoder\" } are not used.\n\n  bst.update(dtrain, iteration=i, fobj=obj)\n/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [08:22:18] WARNING: /workspace/src/learner.cc:738: \nParameters: { \"use_label_encoder\" } are not used.\n\n  bst.update(dtrain, iteration=i, fobj=obj)\n/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [08:22:21] WARNING: /workspace/src/learner.cc:738: \nParameters: { \"use_label_encoder\" } are not used.\n\n  bst.update(dtrain, iteration=i, fobj=obj)\n/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [08:22:29] WARNING: /workspace/src/learner.cc:738: \nParameters: { \"use_label_encoder\" } are not used.\n\n  bst.update(dtrain, iteration=i, fobj=obj)\n/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [08:22:34] WARNING: /workspace/src/learner.cc:738: \nParameters: { \"use_label_encoder\" } are not used.\n\n  bst.update(dtrain, iteration=i, fobj=obj)\n/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [08:22:34] WARNING: /workspace/src/learner.cc:738: \nParameters: { \"use_label_encoder\" } are not used.\n\n  bst.update(dtrain, iteration=i, fobj=obj)\n/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [08:22:38] WARNING: /workspace/src/learner.cc:738: \nParameters: { \"use_label_encoder\" } are not used.\n\n  bst.update(dtrain, iteration=i, fobj=obj)\n/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [08:22:59] WARNING: /workspace/src/learner.cc:738: \nParameters: { \"use_label_encoder\" } are not used.\n\n  bst.update(dtrain, iteration=i, fobj=obj)\n/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [08:23:05] WARNING: /workspace/src/learner.cc:738: \nParameters: { \"use_label_encoder\" } are not used.\n\n  bst.update(dtrain, iteration=i, fobj=obj)\n/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [08:23:07] WARNING: /workspace/src/learner.cc:738: \nParameters: { \"use_label_encoder\" } are not used.\n\n  bst.update(dtrain, iteration=i, fobj=obj)\n/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [08:23:08] WARNING: /workspace/src/learner.cc:738: \nParameters: { \"use_label_encoder\" } are not used.\n\n  bst.update(dtrain, iteration=i, fobj=obj)\n/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [08:23:28] WARNING: /workspace/src/learner.cc:738: \nParameters: { \"use_label_encoder\" } are not used.\n\n  bst.update(dtrain, iteration=i, fobj=obj)\n/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [08:23:29] WARNING: /workspace/src/learner.cc:738: \nParameters: { \"use_label_encoder\" } are not used.\n\n  bst.update(dtrain, iteration=i, fobj=obj)\n/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [08:23:31] WARNING: /workspace/src/learner.cc:738: \nParameters: { \"use_label_encoder\" } are not used.\n\n  bst.update(dtrain, iteration=i, fobj=obj)\n/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [08:23:33] WARNING: /workspace/src/learner.cc:738: \nParameters: { \"use_label_encoder\" } are not used.\n\n  bst.update(dtrain, iteration=i, fobj=obj)\n/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [08:23:50] WARNING: /workspace/src/learner.cc:738: \nParameters: { \"use_label_encoder\" } are not used.\n\n  bst.update(dtrain, iteration=i, fobj=obj)\n/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [08:23:51] WARNING: /workspace/src/learner.cc:738: \nParameters: { \"use_label_encoder\" } are not used.\n\n  bst.update(dtrain, iteration=i, fobj=obj)\n/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [08:23:53] WARNING: /workspace/src/learner.cc:738: \nParameters: { \"use_label_encoder\" } are not used.\n\n  bst.update(dtrain, iteration=i, fobj=obj)\n/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [08:23:54] WARNING: /workspace/src/learner.cc:738: \nParameters: { \"use_label_encoder\" } are not used.\n\n  bst.update(dtrain, iteration=i, fobj=obj)\n/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [08:24:28] WARNING: /workspace/src/learner.cc:738: \nParameters: { \"use_label_encoder\" } are not used.\n\n  bst.update(dtrain, iteration=i, fobj=obj)\n/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [08:24:31] WARNING: /workspace/src/learner.cc:738: \nParameters: { \"use_label_encoder\" } are not used.\n\n  bst.update(dtrain, iteration=i, fobj=obj)\n","output_type":"stream"},{"name":"stdout","text":"Best XGB params: {'learning_rate': 0.2, 'max_depth': 9, 'n_estimators': 200, 'subsample': 0.8}\nBest XGB score: 0.9936\n","output_type":"stream"}],"execution_count":14},{"cell_type":"markdown","source":"## Optimize best models for credit card data\n","metadata":{"id":"hnj-vkpFQDlD"}},{"cell_type":"code","source":"\nprint(\"Optimizing models for Credit Card Data...\")\n\n# Use SMOTE for optimization\nX_cc_smote, y_cc_smote = apply_sampling_strategy(X_cc_train, y_cc_train, 'smote')\n\noptimized_cc_models = {}\n\n# Optimize Random Forest\nprint(\"\\nOptimizing Random Forest...\")\nrf_cc_optimized, rf_cc_best_params, rf_cc_best_score = optimize_model(\n    RandomForestClassifier(class_weight='balanced', random_state=42),\n    param_grids['RandomForestClassifier'],\n    X_cc_smote, y_cc_smote\n)\noptimized_cc_models['Random Forest'] = rf_cc_optimized\nprint(f\"Best RF params: {rf_cc_best_params}\")\nprint(f\"Best RF score: {rf_cc_best_score:.4f}\")\n\n# Optimize XGBoost\nprint(\"\\nOptimizing XGBoost...\")\nxgb_cc_optimized, xgb_cc_best_params, xgb_cc_best_score = optimize_model(\n    xgb.XGBClassifier(random_state=42, eval_metric='logloss', use_label_encoder=False),\n    param_grids['XGBClassifier'],\n    X_cc_smote, y_cc_smote\n)\noptimized_cc_models['XGBoost'] = xgb_cc_optimized\nprint(f\"Best XGB params: {xgb_cc_best_params}\")\nprint(f\"Best XGB score: {xgb_cc_best_score:.4f}\")","metadata":{"id":"84CZwHBRQDlE","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 7. Final Model Evaluation","metadata":{"id":"rxqQokEZQDlE"}},{"cell_type":"code","source":"print(\"FINAL OPTIMIZED MODEL EVALUATION\")\nprint(\"=\" * 50)\n\nfinal_results = []\n\n# Evaluate fraud models\nprint(\"E-commerce Fraud Detection - Optimized Models:\")\nfor model_name, model in optimized_fraud_models.items():\n    results, _, _ = evaluate_model(model, X_fraud_test, y_fraud_test, f\"Fraud-{model_name}\")\n    results['Dataset'] = 'E-commerce Fraud'\n    final_results.append(results)\n    print(f\"{model_name}: F1={results['F1-Score']:.4f}, Precision={results['Precision']:.4f}, Recall={results['Recall']:.4f}\")\n\n# Evaluate credit card models\nprint(\"\\nCredit Card Fraud Detection - Optimized Models:\")\nfor model_name, model in optimized_cc_models.items():\n    results, _, _ = evaluate_model(model, X_cc_test, y_cc_test, f\"CC-{model_name}\")\n    results['Dataset'] = 'Credit Card Fraud'\n    final_results.append(results)\n    print(f\"{model_name}: F1={results['F1-Score']:.4f}, Precision={results['Precision']:.4f}, Recall={results['Recall']:.4f}\")\n\n# Create final results dataframe\nfinal_results_df = pd.DataFrame(final_results)\nprint(\"\\nFinal Results Summary:\")\nprint(final_results_df.round(4))","metadata":{"id":"EH8gt290QDlE","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 8. Model Comparison Visualization","metadata":{"id":"mvfGNmr7QDlE"}},{"cell_type":"code","source":"fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n\n# Fraud data results\nfraud_viz_data = fraud_results_df.head(10)  # Top 10 models\n\n# F1-Score comparison\nfraud_viz_data.plot(x='Model', y='F1-Score', kind='bar', ax=axes[0,0], color='coral')\naxes[0,0].set_title('E-commerce Fraud - F1-Score Comparison', fontweight='bold')\naxes[0,0].tick_params(axis='x', rotation=45)\naxes[0,0].set_ylabel('F1-Score')\n\n# Precision vs Recall\naxes[0,1].scatter(fraud_viz_data['Recall'], fraud_viz_data['Precision'],\n                 c=fraud_viz_data['F1-Score'], cmap='viridis', s=100)\naxes[0,1].set_xlabel('Recall')\naxes[0,1].set_ylabel('Precision')\naxes[0,1].set_title('E-commerce Fraud - Precision vs Recall', fontweight='bold')\n\n# Credit card data results\ncc_viz_data = cc_results_df.head(10)  # Top 10 models\n\n# F1-Score comparison\ncc_viz_data.plot(x='Model', y='F1-Score', kind='bar', ax=axes[1,0], color='lightblue')\naxes[1,0].set_title('Credit Card Fraud - F1-Score Comparison', fontweight='bold')\naxes[1,0].tick_params(axis='x', rotation=45)\naxes[1,0].set_ylabel('F1-Score')\n\n# Precision vs Recall\naxes[1,1].scatter(cc_viz_data['Recall'], cc_viz_data['Precision'],\n                 c=cc_viz_data['F1-Score'], cmap='plasma', s=100)\naxes[1,1].set_xlabel('Recall')\naxes[1,1].set_ylabel('Precision')\naxes[1,1].set_title('Credit Card Fraud - Precision vs Recall', fontweight='bold')\n\nplt.tight_layout()\nplt.show()","metadata":{"id":"VbVFRFaoQDlE","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 9. Save Models and Results","metadata":{"id":"IrNXtsCOQDlE"}},{"cell_type":"code","source":"import os\nimport pickle\nimport joblib\n\n# Ensure results directory exists\nos.makedirs('./results', exist_ok=True)\n\n# Save results\nfraud_results_df.to_csv('./results/fraud_model_results.csv', index=False)\ncc_results_df.to_csv('./results/creditcard_model_results.csv', index=False)\nfinal_results_df.to_csv('./results/final_optimized_results.csv', index=False)\n\n# Save best models dictionary\nbest_models = {\n    'fraud_models': optimized_fraud_models,\n    'cc_models': optimized_cc_models,\n    'fraud_best_model_name': best_fraud_model['Model'],\n    'cc_best_model_name': best_cc_model['Model']\n}\nwith open('./results/best_models.pkl', 'wb') as f:\n    pickle.dump(best_models, f)\n\n# Save individual optimized models\nfor name, model in optimized_fraud_models.items():\n    joblib.dump(model, f'./results/fraud_{name.lower().replace(\" \", \"_\")}_optimized.pkl')\n\nfor name, model in optimized_cc_models.items():\n    joblib.dump(model, f'./results/cc_{name.lower().replace(\" \", \"_\")}_optimized.pkl')\n\n# Summary\nprint(\"All models and results saved successfully!\")\nprint(\"\\nSaved files:\")\nprint(\"- fraud_model_results.csv\")\nprint(\"- creditcard_model_results.csv\")\nprint(\"- final_optimized_results.csv\")\nprint(\"- best_models.pkl\")\nprint(\"- Individual optimized model files\")\n","metadata":{"id":"O1prPUHyQDlF","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Retry Gradient Boosting training with SMOTE for Credit Card Data with error handling\nprint(\"\\nRetrying Gradient Boosting with SMOTE on Credit Card Data...\")\n\nsampling_strategy = 'smote'\nmodel_name = 'Gradient Boosting'\n\ntry:\n    # Apply sampling\n    X_cc_resampled, y_cc_resampled = apply_sampling_strategy(\n        X_cc_train, y_cc_train, strategy=sampling_strategy\n    )\n\n    # Get model\n    models = get_models()\n    model = models[model_name]\n\n    print(f\"\\nTraining {model_name} with {sampling_strategy.upper()}...\")\n\n    # Train model\n    model.fit(X_cc_resampled, y_cc_resampled)\n\n    # Evaluate\n    results, y_pred, y_pred_proba = evaluate_model(\n        model, X_cc_test, y_cc_test,\n        f\"{model_name} ({sampling_strategy})\"\n    )\n\n    results['Sampling'] = sampling_strategy\n    cc_results.append(results)\n\n    # Store model\n    key = f\"{model_name}_{sampling_strategy}\"\n    cc_models[key] = model\n\n    print(f\"F1-Score: {results['F1-Score']:.4f}, Precision: {results['Precision']:.4f}, Recall: {results['Recall']:.4f}\")\n    print(f\"Successfully trained and evaluated {model_name} with {sampling_strategy.upper()}\")\n\nexcept Exception as e:\n    print(f\"Error training {model_name} with {sampling_strategy.upper()}: {str(e)}\")\n\nprint(\"\\nRetry attempt completed.\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7bf1fc6a","outputId":"15ffc920-2c19-47c5-dbbd-1c443d2522fa","trusted":true},"outputs":[],"execution_count":null}]}