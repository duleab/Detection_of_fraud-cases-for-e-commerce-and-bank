{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fraud Detection - Model Training and Imbalanced Data Handling\n",
    "\n",
    "This notebook focuses on training various machine learning models for fraud detection while addressing the class imbalance challenge.\n",
    "\n",
    "## Objectives:\n",
    "1. Load preprocessed data\n",
    "2. Implement techniques for handling class imbalance\n",
    "3. Train multiple machine learning models\n",
    "4. Optimize hyperparameters\n",
    "5. Compare model performances\n",
    "6. Select best models for each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'xgboost'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m-------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                     Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msvm\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SVC\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mneural_network\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MLPClassifier\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mxgboost\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mxgb\u001b[39;00m\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlightgbm\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlgb\u001b[39;00m\n\u001b[32m     18\u001b[39m \u001b[38;5;66;03m# Imbalanced Learning\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'xgboost'"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import warnings\n",
    "from collections import Counter\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "# Imbalanced Learning\n",
    "from imblearn.over_sampling import SMOTE, ADASYN, BorderlineSMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler, EditedNearestNeighbours\n",
    "from imblearn.combine import SMOTETomek, SMOTEENN\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier, BalancedBaggingClassifier\n",
    "\n",
    "# Model Selection and Evaluation\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score, f1_score, precision_score, recall_score\n",
    "\n",
    "# Utilities\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from tqdm import tqdm\n",
    "import joblib\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Preprocessed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load preprocessed data\n",
    "print(\"Loading preprocessed data...\")\n",
    "\n",
    "# Fraud data\n",
    "X_fraud_train = pd.read_csv('../results/X_fraud_train_scaled.csv')\n",
    "X_fraud_test = pd.read_csv('../results/X_fraud_test_scaled.csv')\n",
    "y_fraud_train = pd.read_csv('../results/y_fraud_train.csv').squeeze()\n",
    "y_fraud_test = pd.read_csv('../results/y_fraud_test.csv').squeeze()\n",
    "\n",
    "# Credit card data\n",
    "X_cc_train = pd.read_csv('../results/X_cc_train_scaled.csv')\n",
    "X_cc_test = pd.read_csv('../results/X_cc_test_scaled.csv')\n",
    "y_cc_train = pd.read_csv('../results/y_cc_train.csv').squeeze()\n",
    "y_cc_test = pd.read_csv('../results/y_cc_test.csv').squeeze()\n",
    "\n",
    "# Load feature information\n",
    "with open('../results/feature_info.pkl', 'rb') as f:\n",
    "    feature_info = pickle.load(f)\n",
    "\n",
    "print(f\"Fraud data - Train: {X_fraud_train.shape}, Test: {X_fraud_test.shape}\")\n",
    "print(f\"Credit card data - Train: {X_cc_train.shape}, Test: {X_cc_test.shape}\")\n",
    "\n",
    "# Check class distribution\n",
    "print(f\"\\nFraud data class distribution: {Counter(y_fraud_train)}\")\n",
    "print(f\"Credit card data class distribution: {Counter(y_cc_train)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Imbalanced Data Handling Techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1 Define sampling strategies\n",
    "\n",
    "def apply_sampling_strategy(X, y, strategy='smote', random_state=42):\n",
    "    \"\"\"Apply different sampling strategies to handle imbalanced data\"\"\"\n",
    "    \n",
    "    if strategy == 'none':\n",
    "        return X, y\n",
    "    \n",
    "    elif strategy == 'smote':\n",
    "        sampler = SMOTE(random_state=random_state)\n",
    "    \n",
    "    elif strategy == 'adasyn':\n",
    "        sampler = ADASYN(random_state=random_state)\n",
    "    \n",
    "    elif strategy == 'borderline_smote':\n",
    "        sampler = BorderlineSMOTE(random_state=random_state)\n",
    "    \n",
    "    elif strategy == 'smote_tomek':\n",
    "        sampler = SMOTETomek(random_state=random_state)\n",
    "    \n",
    "    elif strategy == 'smote_enn':\n",
    "        sampler = SMOTEENN(random_state=random_state)\n",
    "    \n",
    "    elif strategy == 'random_undersample':\n",
    "        sampler = RandomUnderSampler(random_state=random_state)\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(f\"Unknown sampling strategy: {strategy}\")\n",
    "    \n",
    "    X_resampled, y_resampled = sampler.fit_resample(X, y)\n",
    "    \n",
    "    print(f\"Original distribution: {Counter(y)}\")\n",
    "    print(f\"Resampled distribution: {Counter(y_resampled)}\")\n",
    "    \n",
    "    return X_resampled, y_resampled\n",
    "\n",
    "# Test different sampling strategies\n",
    "sampling_strategies = ['none', 'smote', 'adasyn', 'borderline_smote', 'smote_tomek']\n",
    "\n",
    "print(\"Available sampling strategies:\", sampling_strategies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.1 Define models with class weight handling\n",
    "\n",
    "def get_models(class_weight='balanced'):\n",
    "    \"\"\"Get dictionary of models with appropriate class weights\"\"\"\n",
    "    \n",
    "    models = {\n",
    "        'Logistic Regression': LogisticRegression(\n",
    "            class_weight=class_weight, \n",
    "            random_state=42, \n",
    "            max_iter=1000\n",
    "        ),\n",
    "        \n",
    "        'Random Forest': RandomForestClassifier(\n",
    "            class_weight=class_weight,\n",
    "            random_state=42,\n",
    "            n_estimators=100\n",
    "        ),\n",
    "        \n",
    "        'Balanced Random Forest': BalancedRandomForestClassifier(\n",
    "            random_state=42,\n",
    "            n_estimators=100\n",
    "        ),\n",
    "        \n",
    "        'XGBoost': xgb.XGBClassifier(\n",
    "            random_state=42,\n",
    "            eval_metric='logloss',\n",
    "            use_label_encoder=False\n",
    "        ),\n",
    "        \n",
    "        'LightGBM': lgb.LGBMClassifier(\n",
    "            random_state=42,\n",
    "            class_weight=class_weight,\n",
    "            verbose=-1\n",
    "        ),\n",
    "        \n",
    "        'Gradient Boosting': GradientBoostingClassifier(\n",
    "            random_state=42\n",
    "        )\n",
    "    }\n",
    "    \n",
    "    return models\n",
    "\n",
    "print(\"Model definitions created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.2 Evaluation metrics function\n",
    "\n",
    "def evaluate_model(model, X_test, y_test, model_name='Model'):\n",
    "    \"\"\"Comprehensive model evaluation\"\"\"\n",
    "    \n",
    "    # Predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1] if hasattr(model, 'predict_proba') else None\n",
    "    \n",
    "    # Calculate metrics\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    \n",
    "    if y_pred_proba is not None:\n",
    "        roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        pr_auc = average_precision_score(y_test, y_pred_proba)\n",
    "    else:\n",
    "        roc_auc = None\n",
    "        pr_auc = None\n",
    "    \n",
    "    results = {\n",
    "        'Model': model_name,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1-Score': f1,\n",
    "        'ROC-AUC': roc_auc,\n",
    "        'PR-AUC': pr_auc\n",
    "    }\n",
    "    \n",
    "    return results, y_pred, y_pred_proba\n",
    "\n",
    "print(\"Evaluation function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Training - Fraud Data (E-commerce)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.1 Train models on fraud data with different sampling strategies\n",
    "\n",
    "fraud_results = []\n",
    "fraud_models = {}\n",
    "\n",
    "print(\"Training models on E-commerce Fraud Data...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Test different sampling strategies\n",
    "best_sampling_strategies = ['none', 'smote', 'borderline_smote']\n",
    "\n",
    "for sampling_strategy in best_sampling_strategies:\n",
    "    print(f\"\\n--- Sampling Strategy: {sampling_strategy.upper()} ---\")\n",
    "    \n",
    "    # Apply sampling\n",
    "    X_fraud_resampled, y_fraud_resampled = apply_sampling_strategy(\n",
    "        X_fraud_train, y_fraud_train, strategy=sampling_strategy\n",
    "    )\n",
    "    \n",
    "    # Get models\n",
    "    models = get_models()\n",
    "    \n",
    "    for model_name, model in models.items():\n",
    "        print(f\"\\nTraining {model_name}...\")\n",
    "        \n",
    "        try:\n",
    "            # Train model\n",
    "            model.fit(X_fraud_resampled, y_fraud_resampled)\n",
    "            \n",
    "            # Evaluate\n",
    "            results, y_pred, y_pred_proba = evaluate_model(\n",
    "                model, X_fraud_test, y_fraud_test, \n",
    "                f\"{model_name} ({sampling_strategy})\"\n",
    "            )\n",
    "            \n",
    "            results['Sampling'] = sampling_strategy\n",
    "            fraud_results.append(results)\n",
    "            \n",
    "            # Store best models\n",
    "            key = f\"{model_name}_{sampling_strategy}\"\n",
    "            fraud_models[key] = model\n",
    "            \n",
    "            print(f\"F1-Score: {results['F1-Score']:.4f}, Precision: {results['Precision']:.4f}, Recall: {results['Recall']:.4f}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error training {model_name}: {str(e)}\")\n",
    "            continue\n",
    "\n",
    "print(\"\\nFraud data model training completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.2 Display fraud data results\n",
    "\n",
    "fraud_results_df = pd.DataFrame(fraud_results)\n",
    "fraud_results_df = fraud_results_df.sort_values('F1-Score', ascending=False)\n",
    "\n",
    "print(\"E-COMMERCE FRAUD DETECTION RESULTS:\")\n",
    "print(\"=\" * 60)\n",
    "print(fraud_results_df.round(4))\n",
    "\n",
    "# Best model for fraud data\n",
    "best_fraud_model = fraud_results_df.iloc[0]\n",
    "print(f\"\\nBest Model for E-commerce Fraud: {best_fraud_model['Model']}\")\n",
    "print(f\"F1-Score: {best_fraud_model['F1-Score']:.4f}\")\n",
    "print(f\"Precision: {best_fraud_model['Precision']:.4f}\")\n",
    "print(f\"Recall: {best_fraud_model['Recall']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Training - Credit Card Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.1 Train models on credit card data\n",
    "\n",
    "cc_results = []\n",
    "cc_models = {}\n",
    "\n",
    "print(\"Training models on Credit Card Data...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Test different sampling strategies\n",
    "for sampling_strategy in best_sampling_strategies:\n",
    "    print(f\"\\n--- Sampling Strategy: {sampling_strategy.upper()} ---\")\n",
    "    \n",
    "    # Apply sampling\n",
    "    X_cc_resampled, y_cc_resampled = apply_sampling_strategy(\n",
    "        X_cc_train, y_cc_train, strategy=sampling_strategy\n",
    "    )\n",
    "    \n",
    "    # Get models\n",
    "    models = get_models()\n",
    "    \n",
    "    for model_name, model in models.items():\n",
    "        print(f\"\\nTraining {model_name}...\")\n",
    "        \n",
    "        try:\n",
    "            # Train model\n",
    "            model.fit(X_cc_resampled, y_cc_resampled)\n",
    "            \n",
    "            # Evaluate\n",
    "            results, y_pred, y_pred_proba = evaluate_model(\n",
    "                model, X_cc_test, y_cc_test, \n",
    "                f\"{model_name} ({sampling_strategy})\"\n",
    "            )\n",
    "            \n",
    "            results['Sampling'] = sampling_strategy\n",
    "            cc_results.append(results)\n",
    "            \n",
    "            # Store best models\n",
    "            key = f\"{model_name}_{sampling_strategy}\"\n",
    "            cc_models[key] = model\n",
    "            \n",
    "            print(f\"F1-Score: {results['F1-Score']:.4f}, Precision: {results['Precision']:.4f}, Recall: {results['Recall']:.4f}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error training {model_name}: {str(e)}\")\n",
    "            continue\n",
    "\n",
    "print(\"\\nCredit card data model training completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.2 Display credit card results\n",
    "\n",
    "cc_results_df = pd.DataFrame(cc_results)\n",
    "cc_results_df = cc_results_df.sort_values('F1-Score', ascending=False)\n",
    "\n",
    "print(\"CREDIT CARD FRAUD DETECTION RESULTS:\")\n",
    "print(\"=\" * 60)\n",
    "print(cc_results_df.round(4))\n",
    "\n",
    "# Best model for credit card data\n",
    "best_cc_model = cc_results_df.iloc[0]\n",
    "print(f\"\\nBest Model for Credit Card Fraud: {best_cc_model['Model']}\")\n",
    "print(f\"F1-Score: {best_cc_model['F1-Score']:.4f}\")\n",
    "print(f\"Precision: {best_cc_model['Precision']:.4f}\")\n",
    "print(f\"Recall: {best_cc_model['Recall']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.1 Hyperparameter tuning for best models\n",
    "\n",
    "def optimize_model(model_class, param_grid, X_train, y_train, cv=3, scoring='f1'):\n",
    "    \"\"\"Optimize hyperparameters using GridSearchCV\"\"\"\n",
    "    \n",
    "    grid_search = GridSearchCV(\n",
    "        model_class,\n",
    "        param_grid,\n",
    "        cv=StratifiedKFold(n_splits=cv, shuffle=True, random_state=42),\n",
    "        scoring=scoring,\n",
    "        n_jobs=-1,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    return grid_search.best_estimator_, grid_search.best_params_, grid_search.best_score_\n",
    "\n",
    "# Define parameter grids for top models\n",
    "param_grids = {\n",
    "    'RandomForestClassifier': {\n",
    "        'n_estimators': [100, 200],\n",
    "        'max_depth': [10, 20, None],\n",
    "        'min_samples_split': [2, 5],\n",
    "        'min_samples_leaf': [1, 2]\n",
    "    },\n",
    "    \n",
    "    'XGBClassifier': {\n",
    "        'n_estimators': [100, 200],\n",
    "        'max_depth': [3, 6, 9],\n",
    "        'learning_rate': [0.01, 0.1, 0.2],\n",
    "        'subsample': [0.8, 1.0]\n",
    "    },\n",
    "    \n",
    "    'LGBMClassifier': {\n",
    "        'n_estimators': [100, 200],\n",
    "        'max_depth': [3, 6, 9],\n",
    "        'learning_rate': [0.01, 0.1, 0.2],\n",
    "        'num_leaves': [31, 50, 100]\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"Hyperparameter optimization setup completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.2 Optimize best models for fraud data\n",
    "\n",
    "print(\"Optimizing models for E-commerce Fraud Data...\")\n",
    "\n",
    "# Use SMOTE for optimization (generally performs well)\n",
    "X_fraud_smote, y_fraud_smote = apply_sampling_strategy(X_fraud_train, y_fraud_train, 'smote')\n",
    "\n",
    "optimized_fraud_models = {}\n",
    "\n",
    "# Optimize Random Forest\n",
    "print(\"\\nOptimizing Random Forest...\")\n",
    "rf_optimized, rf_best_params, rf_best_score = optimize_model(\n",
    "    RandomForestClassifier(class_weight='balanced', random_state=42),\n",
    "    param_grids['RandomForestClassifier'],\n",
    "    X_fraud_smote, y_fraud_smote\n",
    ")\n",
    "optimized_fraud_models['Random Forest'] = rf_optimized\n",
    "print(f\"Best RF params: {rf_best_params}\")\n",
    "print(f\"Best RF score: {rf_best_score:.4f}\")\n",
    "\n",
    "# Optimize XGBoost\n",
    "print(\"\\nOptimizing XGBoost...\")\n",
    "xgb_optimized, xgb_best_params, xgb_best_score = optimize_model(\n",
    "    xgb.XGBClassifier(random_state=42, eval_metric='logloss', use_label_encoder=False),\n",
    "    param_grids['XGBClassifier'],\n",
    "    X_fraud_smote, y_fraud_smote\n",
    ")\n",
    "optimized_fraud_models['XGBoost'] = xgb_optimized\n",
    "print(f\"Best XGB params: {xgb_best_params}\")\n",
    "print(f\"Best XGB score: {xgb_best_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.3 Optimize best models for credit card data\n",
    "\n",
    "print(\"Optimizing models for Credit Card Data...\")\n",
    "\n",
    "# Use SMOTE for optimization\n",
    "X_cc_smote, y_cc_smote = apply_sampling_strategy(X_cc_train, y_cc_train, 'smote')\n",
    "\n",
    "optimized_cc_models = {}\n",
    "\n",
    "# Optimize Random Forest\n",
    "print(\"\\nOptimizing Random Forest...\")\n",
    "rf_cc_optimized, rf_cc_best_params, rf_cc_best_score = optimize_model(\n",
    "    RandomForestClassifier(class_weight='balanced', random_state=42),\n",
    "    param_grids['RandomForestClassifier'],\n",
    "    X_cc_smote, y_cc_smote\n",
    ")\n",
    "optimized_cc_models['Random Forest'] = rf_cc_optimized\n",
    "print(f\"Best RF params: {rf_cc_best_params}\")\n",
    "print(f\"Best RF score: {rf_cc_best_score:.4f}\")\n",
    "\n",
    "# Optimize XGBoost\n",
    "print(\"\\nOptimizing XGBoost...\")\n",
    "xgb_cc_optimized, xgb_cc_best_params, xgb_cc_best_score = optimize_model(\n",
    "    xgb.XGBClassifier(random_state=42, eval_metric='logloss', use_label_encoder=False),\n",
    "    param_grids['XGBClassifier'],\n",
    "    X_cc_smote, y_cc_smote\n",
    ")\n",
    "optimized_cc_models['XGBoost'] = xgb_cc_optimized\n",
    "print(f\"Best XGB params: {xgb_cc_best_params}\")\n",
    "print(f\"Best XGB score: {xgb_cc_best_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Final Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7.1 Evaluate optimized models\n",
    "\n",
    "print(\"FINAL OPTIMIZED MODEL EVALUATION\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "final_results = []\n",
    "\n",
    "# Evaluate fraud models\n",
    "print(\"E-commerce Fraud Detection - Optimized Models:\")\n",
    "for model_name, model in optimized_fraud_models.items():\n",
    "    results, _, _ = evaluate_model(model, X_fraud_test, y_fraud_test, f\"Fraud-{model_name}\")\n",
    "    results['Dataset'] = 'E-commerce Fraud'\n",
    "    final_results.append(results)\n",
    "    print(f\"{model_name}: F1={results['F1-Score']:.4f}, Precision={results['Precision']:.4f}, Recall={results['Recall']:.4f}\")\n",
    "\n",
    "# Evaluate credit card models\n",
    "print(\"\\nCredit Card Fraud Detection - Optimized Models:\")\n",
    "for model_name, model in optimized_cc_models.items():\n",
    "    results, _, _ = evaluate_model(model, X_cc_test, y_cc_test, f\"CC-{model_name}\")\n",
    "    results['Dataset'] = 'Credit Card Fraud'\n",
    "    final_results.append(results)\n",
    "    print(f\"{model_name}: F1={results['F1-Score']:.4f}, Precision={results['Precision']:.4f}, Recall={results['Recall']:.4f}\")\n",
    "\n",
    "# Create final results dataframe\n",
    "final_results_df = pd.DataFrame(final_results)\n",
    "print(\"\\nFinal Results Summary:\")\n",
    "print(final_results_df.round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Model Comparison Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8.1 Visualize model performance comparison\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# Fraud data results\n",
    "fraud_viz_data = fraud_results_df.head(10)  # Top 10 models\n",
    "\n",
    "# F1-Score comparison\n",
    "fraud_viz_data.plot(x='Model', y='F1-Score', kind='bar', ax=axes[0,0], color='coral')\n",
    "axes[0,0].set_title('E-commerce Fraud - F1-Score Comparison', fontweight='bold')\n",
    "axes[0,0].tick_params(axis='x', rotation=45)\n",
    "axes[0,0].set_ylabel('F1-Score')\n",
    "\n",
    "# Precision vs Recall\n",
    "axes[0,1].scatter(fraud_viz_data['Recall'], fraud_viz_data['Precision'], \n",
    "                 c=fraud_viz_data['F1-Score'], cmap='viridis', s=100)\n",
    "axes[0,1].set_xlabel('Recall')\n",
    "axes[0,1].set_ylabel('Precision')\n",
    "axes[0,1].set_title('E-commerce Fraud - Precision vs Recall', fontweight='bold')\n",
    "\n",
    "# Credit card data results\n",
    "cc_viz_data = cc_results_df.head(10)  # Top 10 models\n",
    "\n",
    "# F1-Score comparison\n",
    "cc_viz_data.plot(x='Model', y='F1-Score', kind='bar', ax=axes[1,0], color='lightblue')\n",
    "axes[1,0].set_title('Credit Card Fraud - F1-Score Comparison', fontweight='bold')\n",
    "axes[1,0].tick_params(axis='x', rotation=45)\n",
    "axes[1,0].set_ylabel('F1-Score')\n",
    "\n",
    "# Precision vs Recall\n",
    "axes[1,1].scatter(cc_viz_data['Recall'], cc_viz_data['Precision'], \n",
    "                 c=cc_viz_data['F1-Score'], cmap='plasma', s=100)\n",
    "axes[1,1].set_xlabel('Recall')\n",
    "axes[1,1].set_ylabel('Precision')\n",
    "axes[1,1].set_title('Credit Card Fraud - Precision vs Recall', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Save Models and Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9.1 Save all results and models\n",
    "\n",
    "# Save results\n",
    "fraud_results_df.to_csv('../results/fraud_model_results.csv', index=False)\n",
    "cc_results_df.to_csv('../results/creditcard_model_results.csv', index=False)\n",
    "final_results_df.to_csv('../results/final_optimized_results.csv', index=False)\n",
    "\n",
    "# Save best models\n",
    "best_models = {\n",
    "    'fraud_models': optimized_fraud_models,\n",
    "    'cc_models': optimized_cc_models,\n",
    "    'fraud_best_model_name': best_fraud_model['Model'],\n",
    "    'cc_best_model_name': best_cc_model['Model']\n",
    "}\n",
    "\n",
    "with open('../results/best_models.pkl', 'wb') as f:\n",
    "    pickle.dump(best_models, f)\n",
    "\n",
    "# Save individual optimized models\n",
    "for name, model in optimized_fraud_models.items():\n",
    "    joblib.dump(model, f'../results/fraud_{name.lower().replace(\" \", \"_\")}_optimized.pkl')\n",
    "\n",
    "for name, model in optimized_cc_models.items():\n",
    "    joblib.dump(model, f'../results/cc_{name.lower().replace(\" \", \"_\")}_optimized.pkl')\n",
    "\n",
    "print(\"All models and results saved successfully!\")\n",
    "print(\"\\nSaved files:\")\n",
    "print(\"- fraud_model_results.csv\")\n",
    "print(\"- creditcard_model_results.csv\")\n",
    "print(\"- final_optimized_results.csv\")\n",
    "print(\"- best_models.pkl\")\n",
    "print(\"- Individual optimized model files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Model Training Summary\n",
    "\n",
    "### Key Findings:\n",
    "\n",
    "#### Sampling Strategies:\n",
    "- **SMOTE**: Generally provides good balance between precision and recall\n",
    "- **Borderline SMOTE**: Often performs better on highly imbalanced datasets\n",
    "- **No Sampling + Class Weights**: Can work well with ensemble methods\n",
    "\n",
    "#### Model Performance:\n",
    "- **Tree-based models** (Random Forest, XGBoost, LightGBM) typically perform best\n",
    "- **Ensemble methods** handle imbalanced data better\n",
    "- **Hyperparameter optimization** significantly improves performance\n",
    "\n",
    "#### Evaluation Metrics:\n",
    "- **F1-Score**: Best overall metric for imbalanced classification\n",
    "- **Precision**: Important for minimizing false positives\n",
    "- **Recall**: Critical for catching actual fraud cases\n",
    "- **PR-AUC**: Better than ROC-AUC for imbalanced datasets\n",
    "\n",
    "### Next Steps:\n",
    "1. Detailed model evaluation with confusion matrices\n",
    "2. Model interpretation using SHAP values\n",
    "3. Business impact analysis\n",
    "4. Production deployment considerations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
